{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04adde7a",
   "metadata": {},
   "source": [
    "# <center>Bag of words (Bow)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3e485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a61b28",
   "metadata": {},
   "source": [
    "Our most important columns summary and text both are in textual format. We need to convernt it to numbers or neumeric vector. <br>\n",
    "Out of many techniques, BOW is used here\n",
    "#### Single row text is called document and collection of all reviews(text column in this case) is called corpus.\n",
    "#### To create BOW, we take all the unique words in our corpus and create d dimentional array.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/bow_intro.jpg\" width=\"500px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4748d",
   "metadata": {},
   "source": [
    "There is also another variant of BOW: called boolean bow or binary bow. <br>\n",
    "<hr />\n",
    "\n",
    "# Text preprocessing\n",
    "## 1. Stop-words removal\n",
    "\n",
    "Many words like \"is, and, this,\" etc are not so important. We can remove them from our corpus. <br>\n",
    "It results out bow vector to be small and more meaningful most of the time. However, removing stop words are not always a best choice <br>\n",
    "\n",
    "if there is \"not\" in stop-words then it can totally change the meaning of the sentence. <br>\n",
    "Example: <br>\n",
    "t1 = This phone is good. <br>\n",
    "t2 = This phone is not good. <br>\n",
    "After removing \"not\", both sentence would mean same but they are totally opposite\n",
    "\n",
    "## 2. Make everything in lowercase\n",
    "## 3. Stemming\n",
    "\n",
    "Stemming is all about taking words which are related and convert them to their stem form. <br>\n",
    "For example: <br>\n",
    "taseful and tasty both mean => taste <br>\n",
    "changing, changed => change\n",
    "\n",
    "## 4. Lemmatization\n",
    "Breaking a sentence into words. <br>\n",
    "Lemmatization is one of the most common text pre-processing techniques used in natural language processing (NLP) and machine learning in general. Lemmatization is not that much different than the stemming of words in NLP. In both stemming and lemmatization, we try to reduce a given word to its root word. The root word is called a stem in the stemming process, and itâ€™s called a lemma in the lemmatization process. But there are a few more differences to the two than that.\n",
    "\n",
    "# One of the major issues of BOW is it ignores the semantics\n",
    "\n",
    "It represents \"good\" and \"nice\" as two different words (two seperate dimentions) but in english they are closely related. It ignores the synonyms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf0b81c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Uni-gram, bi-gram and n-gram\n",
    "\n",
    "t1 = this phone is good and cheap <br>\n",
    "t2 = this phone is not good and cheap <br>\n",
    "\n",
    "lets assume there two texts are two different reviews. After removing stop-words it would look as follow: <br> \n",
    "\n",
    "t1 = phone good cheap <br>\n",
    "t2 = phone good cheap <br>\n",
    "\n",
    "So after removing stop-words (if \"not\" is in stop-words), both sentences are exactly same but it was two different reviews with oppposite meaning.\n",
    "\n",
    "### Just using uni-gram discards the dequence information. so with n-gram we will be considering n words in a dimention.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/n-gram.jpg\" width=\"600px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89873488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31b0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b75840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c80e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba276c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060cadf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
